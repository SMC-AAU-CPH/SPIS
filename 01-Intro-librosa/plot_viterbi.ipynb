{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Viterbi decoding\n\nThis notebook demonstrates how to use Viterbi decoding to impose temporal\nsmoothing on frame-wise state predictions.\n\nOur working example will be the problem of silence/non-silence detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Code source: Brian McFee\n# License: ISC\n\n##################\n# Standard imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load an example signal\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y, sr = librosa.load(librosa.ex('trumpet'))\n\n\n# And compute the spectrogram magnitude and phase\nS_full, phase = librosa.magphase(librosa.stft(y))\n\n\n###################\n# Plot the spectrum\nfig, ax = plt.subplots()\nimg = librosa.display.specshow(librosa.amplitude_to_db(S_full, ref=np.max),\n                               y_axis='log', x_axis='time', sr=sr, ax=ax)\nfig.colorbar(img, ax=ax);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, there are periods of silence and\nnon-silence throughout this recording.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# As a first step, we can plot the root-mean-square (RMS) curve\nrms = librosa.feature.rms(y=y)[0]\n\ntimes = librosa.frames_to_time(np.arange(len(rms)))\n\nfig, ax = plt.subplots()\nax.plot(times, rms)\nax.axhline(0.02, color='r', alpha=0.5)\nax.set(xlabel='Time', ylabel='RMS');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The red line at 0.02 indicates a reasonable threshold for silence detection.\nHowever, the RMS curve occasionally dips below the threshold momentarily,\nand we would prefer the detector to not count these brief dips as silence.\nThis is where the Viterbi algorithm comes in handy!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a first step, we will convert the raw RMS score\ninto a likelihood (probability) by logistic mapping\n\n  $P[V=1 | x] = \\frac{\\exp(x - \\tau)}{1 + \\exp(x - \\tau)}$\n\nwhere $x$ denotes the RMS value and $\\tau=0.02$ is our threshold.\nThe variable $V$ indicates whether the signal is non-silent (1) or silent (0).\n\nWe'll normalize the RMS by its standard deviation to expand the\nrange of the probability vector\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r_normalized = (rms - 0.02) / np.std(rms)\np = np.exp(r_normalized) / (1 + np.exp(r_normalized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the probability curve over time:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.plot(times, p, label='P[V=1|x]')\nax.axhline(0.5, color='r', alpha=0.5, label='Descision threshold')\nax.set(xlabel='Time')\nax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "which looks much like the first plot, but with the decision threshold\nshifted to 0.5.  A simple silence detector would classify each frame\nindependently of its neighbors, which would result in the following plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\nfig, ax = plt.subplots(nrows=2, sharex=True)\nlibrosa.display.specshow(librosa.amplitude_to_db(S_full, ref=np.max),\n                         y_axis='log', x_axis='time', sr=sr, ax=ax[0])\nax[0].label_outer()\nax[1].step(times, p>=0.5, label='Non-silent')\nax[1].set(ylim=[0, 1.05])\nax[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do better using the Viterbi algorithm.\nWe'll use state 0 to indicate silent, and 1 to indicate non-silent.\nWe'll assume that a silent frame is equally likely to be followed\nby silence or non-silence, but that non-silence is slightly\nmore likely to be followed by non-silence.\nThis is accomplished by building a self-loop transition matrix,\nwhere `transition[i, j]` is the probability of moving from state\n`i` to state `j` in the next frame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transition = librosa.sequence.transition_loop(2, [0.5, 0.6])\nprint(transition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our `p` variable only indicates the probability of non-silence,\nso we need to also compute the probability of silence as its complement.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "full_p = np.vstack([1 - p, p])\nprint(full_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we're ready to decode!\nWe'll use `viterbi_discriminative` here, since the inputs are\nstate likelihoods conditional on data (in our case, data is rms).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "states = librosa.sequence.viterbi_discriminative(full_p, transition)\n\n# sphinx_gallery_thumbnail_number = 5\nfig, ax = plt.subplots(nrows=2, sharex=True)\nlibrosa.display.specshow(librosa.amplitude_to_db(S_full, ref=np.max),\n                         y_axis='log', x_axis='time', sr=sr, ax=ax[0])\nax[0].label_outer()\nax[1].step(times, p>=0.5, label='Frame-wise')\nax[1].step(times, states, linestyle='--', color='orange', label='Viterbi')\nax[1].set(ylim=[0, 1.05])\nax[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note how the Viterbi output has fewer state changes than the frame-wise\npredictor, and it is less sensitive to momentary dips in energy.\nThis is controlled directly by the transition matrix.\nA higher self-transition probability means that the decoder is less\nlikely to change states.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}