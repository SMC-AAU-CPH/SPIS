{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SMC-AAU-CPH/SPIS/blob/main/04-SharedLab/Audio_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Data Pre-Processing Analysis\n",
        "- Developed by Marcelo Rovai\n",
        "- Audio Capture from the post: [\"Direct access to your webcam and microphone inside Google Colab notebook\"](https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/)"
      ],
      "metadata": {
        "id": "P7Avv6IL2OrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the required packges"
      ],
      "metadata": {
        "id": "OWFN65qfo_3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAHBniOFlbdZ",
        "outputId": "8faf7383-8653-4f06-b4f2-4a7193c93ad2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the Libraries"
      ],
      "metadata": {
        "id": "Q1vlbxXHpz-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.fftpack\n",
        "import scipy.fftpack as fft\n",
        "from scipy.fftpack import dct\n",
        "from scipy.signal import spectrogram\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import librosa\n",
        "import soundfile as sf"
      ],
      "metadata": {
        "id": "AMLm15JmmWDx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define audio functions"
      ],
      "metadata": {
        "id": "vdRNMn4HppOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7SjpbGiwm91H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ],
      "metadata": {
        "id": "JbpBgYwsmlem"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Plot functions"
      ],
      "metadata": {
        "id": "gZRJxTf5hKE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_time(audio, figsize=(5,3), title=''):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(audio, alpha=0.5, label='audio')\n",
        "    plt.grid(True)\n",
        "    plt.title(title+' Sample - Time Domain')\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('amplitude')\n",
        "    plt.show();"
      ],
      "metadata": {
        "id": "cRvd8crlnhrZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fft(data, sample_rate, figsize=(15,4),title = ''):\n",
        "\n",
        "    N = sample_rate\n",
        "    # Compute FFT\n",
        "    yf = scipy.fftpack.fft(data)\n",
        "\n",
        "    # Generate frequency bins\n",
        "    xf = np.linspace(0.0, N//2, N//2)\n",
        "\n",
        "    # Find the index of the maximum amplitude and its corresponding frequency\n",
        "    start_bin = int(20 * (N // 2) / (N // 2))  # Corresponding bin for 20 Hz\n",
        "    max_amplitude_idx = np.argmax(2.0/N * np.abs(yf[start_bin:N//2]))\n",
        "    max_amplitude_frequency = xf[start_bin:][max_amplitude_idx]\n",
        "\n",
        "    # Plot FFT (skipping the first 20 bins to start from 20 Hz)\n",
        "    plt.figure(figsize=figsize)\n",
        "    start_bin = int(20 * (N // 2) / (N // 2))  # Corresponding bin for 20 Hz\n",
        "    plt.semilogx(xf[start_bin:], 2.0/N * np.abs(yf[start_bin:N//2]))\n",
        "\n",
        "    # Add a point and label for the frequency with the maximum amplitude\n",
        "    plt.scatter(max_amplitude_frequency, 2.0/N * np.abs(yf[start_bin:][max_amplitude_idx]), color='red')\n",
        "    plt.annotate(f'Max Amp. @ {max_amplitude_frequency:.2f} Hz',\n",
        "                 (max_amplitude_frequency, 2.0/N * np.abs(yf[start_bin:][max_amplitude_idx])),\n",
        "                 textcoords=\"offset points\",\n",
        "                 xytext=(10,-10),\n",
        "                 ha='left')\n",
        "\n",
        "   # plt.semilogx(2.0/N * np.abs(yf[20:N//2]))\n",
        "    plt.xlabel('frequency [Hz]')\n",
        "    plt.ylabel('amp')\n",
        "    plt.grid(True)\n",
        "    plt.title(title+' sample - Frequency Components')\n",
        "    return yf, max_amplitude_frequency\n",
        "    plt.show();"
      ],
      "metadata": {
        "id": "zST97yf4tpAG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_spectogram(audio, sample_rate, figsize=(10,5), title=''):\n",
        "    epsilon = 1e-10 # Small constant to avoid log10(0)\n",
        "    frequencies, times, Sxx = spectrogram(audio, sample_rate)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.pcolormesh(times, frequencies, 10 * np.log10(Sxx + epsilon), shading='gouraud')\n",
        "    plt.title(title+' Sample - Spectogram')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.colorbar(label='Intensity [dB]')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lr9dYnx4zwx2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_plot_mfcc (audio, sample_rate, n_mfcc=13, figsize=(10,5), title=''):\n",
        "\n",
        "    # Calculate MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "\n",
        "    # # Plotting the MFCCs\n",
        "    plt.figure(figsize=figsize)\n",
        "    librosa.display.specshow(mfccs,\n",
        "                             x_axis='time',\n",
        "                             sr=sample_rate,\n",
        "                             cmap='coolwarm')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.ylabel('MFCC')\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('MFCC Coefficients')\n",
        "    plt.yticks(np.arange(0, 13, 1), [str(i+1) for i in range(13)])\n",
        "    plt.title(title +' - Mel-frequency cepstral coefficients (MFCC)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cgpmUswlzylX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Record and Play a sound sample"
      ],
      "metadata": {
        "id": "uzG_0z-8qOdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yes, sample_rate = get_audio()"
      ],
      "metadata": {
        "id": "2yDCpqVnh6Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no, sample_rate = get_audio()"
      ],
      "metadata": {
        "id": "y51j2ek4fs6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yes.shape, no.shape"
      ],
      "metadata": {
        "id": "r5Q9zFlGJt3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_rate"
      ],
      "metadata": {
        "id": "t3NuMkRxJFCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crop 1-second of data"
      ],
      "metadata": {
        "id": "8GxlJy215Rv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yes = yes[:sample_rate]\n",
        "no = no[:sample_rate]"
      ],
      "metadata": {
        "id": "nEk9oDqdKsP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save samples"
      ],
      "metadata": {
        "id": "E2oXQ5Y05Neb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sf.write('yes.wav', yes, sample_rate)\n",
        "sf.write('no.wav', no, sample_rate)"
      ],
      "metadata": {
        "id": "AWlPaFNCN-8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uIgtIBFlNoec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Plot the samples"
      ],
      "metadata": {
        "id": "th7O-yZIhsam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the saved audio files, resampled as 16KHz\n",
        "> Note that the sample_rate of captured audio data is always 48KHz. We used Librosa to resample it to 16KHz"
      ],
      "metadata": {
        "id": "JJj-q3gaTlTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio file\n",
        "yes, sample_rate = librosa.load(\"yes.wav\", sr=16000, duration=1.0)\n",
        "no, sample_rate = librosa.load(\"no.wav\", sr=16000, duration=1.0)"
      ],
      "metadata": {
        "id": "LCVgPe_4TGGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yes.shape, no.shape, sample_rate"
      ],
      "metadata": {
        "id": "LuZxywUPUNOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_time(yes, figsize = (8,4), title='YES')\n",
        "plot_time(no,  figsize = (8,4), title='NO')"
      ],
      "metadata": {
        "id": "MwgohvFcfPcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calulate and plot the FFT of samples"
      ],
      "metadata": {
        "id": "oGSz2ho15hlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yf_yes, max_amp_freq_yes = fft(yes, sample_rate, figsize = (8,4), title = 'YES')"
      ],
      "metadata": {
        "id": "qQdps1Bft_Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yf_no, max_amp_freq_no = fft(no, sample_rate, figsize = (8,4), title = 'NO')"
      ],
      "metadata": {
        "id": "_dsbhLekgVlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate and Plot spectograms"
      ],
      "metadata": {
        "id": "KIqUOP_Y5qWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_spectogram(yes, sample_rate, figsize = (8,4), title='YES')\n",
        "plot_spectogram(no, sample_rate, figsize = (8,4), title='NO')"
      ],
      "metadata": {
        "id": "8MYSXMFlnEt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate and Plot MFCC"
      ],
      "metadata": {
        "id": "ovtJCrq36ccJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librosa function is designed to handle the entire MFCC extraction process starting from the raw audio signal.\n",
        "\n",
        "When you pass the raw audio signal to `librosa.feature.mfcc`, the function internally performs several steps including:\n",
        "\n",
        "1. Framing the signal into overlapping frames.\n",
        "2. Applying a window function to each frame.\n",
        "3. Calculating the FFT to convert each frame to the frequency domain.\n",
        "4. Applying Mel filter banks to the frequency spectra.\n",
        "5. Taking the logarithm of the Mel frequencies.\n",
        "6. Performing the Discrete Cosine Transform (DCT).\n"
      ],
      "metadata": {
        "id": "px7h09150XjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_plot_mfcc (yes, sample_rate, n_mfcc=13, figsize = (8,4), title='YES')\n",
        "calc_plot_mfcc (no, sample_rate, n_mfcc=13, figsize = (8,4), title='NO')"
      ],
      "metadata": {
        "id": "qY2Kyo_3vMO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating MFCC Features"
      ],
      "metadata": {
        "id": "xRMBJs6lHzCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Librosa Display Library"
      ],
      "metadata": {
        "id": "yTkHK0SKu0Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S = librosa.feature.melspectrogram(y=yes,\n",
        "                                   sr=sample_rate,\n",
        "                                   n_mels=128,\n",
        "                                   fmax=8000)\n",
        "\n",
        "mfccs = librosa.feature.mfcc(y=yes,\n",
        "                             sr=sample_rate,\n",
        "                             n_mfcc=13)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "img = librosa.display.specshow(\n",
        "    librosa.power_to_db(S, ref=np.max),\n",
        "    x_axis='time', y_axis='mel',\n",
        "    fmax=8000,\n",
        "    ax=ax[0])\n",
        "\n",
        "fig.colorbar(img, ax=[ax[0]])\n",
        "ax[0].set(title='Mel spectrogram')\n",
        "ax[0].label_outer()\n",
        "img = librosa.display.specshow(mfccs, x_axis='time', ax=ax[1])\n",
        "fig.colorbar(img, ax=[ax[1]])\n",
        "ax[1].set(title='MFCC')\n"
      ],
      "metadata": {
        "id": "Bdn-3u3hQhE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MFCC Calculation and plot using numpy and scipy libraries"
      ],
      "metadata": {
        "id": "fUJAu2Soq_aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading the audio file**"
      ],
      "metadata": {
        "id": "sJrWWxmhBznk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio = yes"
      ],
      "metadata": {
        "id": "RGZSgDm8sodo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-emphasis**: Apply a pre-emphasis filter to high-pass filter the audio signal:"
      ],
      "metadata": {
        "id": "cuhazue5CCrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.97\n",
        "audio = np.append(audio[0], audio[1:] - alpha * audio[:-1])"
      ],
      "metadata": {
        "id": "tVhNETcG9SEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Framing**: Divide the signal into frames of 20 milliseconds with a stride of 20 milliseconds:"
      ],
      "metadata": {
        "id": "ZdM2kSvZCYDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "frame_size = 0.020  # frame size in seconds\n",
        "frame_stride = 0.020  # frame stride in seconds\n",
        "\n",
        "# Calculate frame length and frame step (convert from seconds to samples)\n",
        "frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate\n",
        "frame_length = int(round(frame_length))\n",
        "frame_step = int(round(frame_step))\n",
        "\n",
        "# Calculate the total number of frames\n",
        "num_frames = int(np.ceil(float(np.abs(len(audio) - frame_length)) / frame_step))\n",
        "\n",
        "frame_length, frame_step, num_frames"
      ],
      "metadata": {
        "id": "G-5qCQ-V9QEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad audio signal\n",
        "pad_audio_length = num_frames * frame_step + frame_length\n",
        "z = np.zeros((pad_audio_length - len(audio)))\n",
        "pad_audio = np.append(audio, z)"
      ],
      "metadata": {
        "id": "f15m2iMSs0-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_audio.shape"
      ],
      "metadata": {
        "id": "ab3s3Ii3tX_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the frames\n",
        "indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "frames = pad_audio[indices.astype(np.int32, copy=False)]"
      ],
      "metadata": {
        "id": "ftYBmPJKtV9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames.shape"
      ],
      "metadata": {
        "id": "ZrO-ea9jtmH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Windowing**: Apply a Hamming window to each frame:"
      ],
      "metadata": {
        "id": "gEuQsa4WCwnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply window function (Hamming)\n",
        "frames *= np.hamming(frame_length)"
      ],
      "metadata": {
        "id": "hwxH0kqsCq34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames[0].shape"
      ],
      "metadata": {
        "id": "rPC0MAY6tuom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_time(frames[10], figsize = (5,3), title='frame[10]')\n",
        "plot_time(frames[25], figsize = (5,3), title='frame[25]')\n",
        "plot_time(frames[40], figsize = (5,3), title='frame[40]')"
      ],
      "metadata": {
        "id": "mOfhNgTEuFjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fast Fourier Transform (FFT)**: Perform FFT to convert the frames to frequency domain:"
      ],
      "metadata": {
        "id": "Qj566l9wC69R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform FFT and calculate power spectrum\n",
        "NFFT = 512\n",
        "mag_frames = np.abs(scipy.fftpack.fft(frames, NFFT))\n",
        "pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))"
      ],
      "metadata": {
        "id": "UX9nqxnItkNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mag_frames.shape, pow_frames.shape"
      ],
      "metadata": {
        "id": "wCvU6bWZvJBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should take only up to `(NFFT/2) + 1` elements after the FFT, as those are the unique frequency components for real-valued signals. And also update the pow_frames calculation."
      ],
      "metadata": {
        "id": "0jgKAXC1ygMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mag_frames = mag_frames[:, :NFFT//2 + 1]\n",
        "pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))"
      ],
      "metadata": {
        "id": "FxDb_RgryX-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mag_frames.shape, pow_frames.shape"
      ],
      "metadata": {
        "id": "lxAQbk3Sy_mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_frame_fft(data, figsize=(5,3), title=''):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(data)\n",
        "    plt.xlabel('FFT Lenght')\n",
        "    plt.ylabel('power')\n",
        "    plt.grid(True)\n",
        "    plt.title(title+' sample - Frequency Components')\n",
        "    plt.show();"
      ],
      "metadata": {
        "id": "uLNpP3NiNexf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_frame_fft(pow_frames[10], title = 'pow_frames[10]')\n",
        "plot_frame_fft(pow_frames[25], title = 'pow_frames[25]')\n",
        "plot_frame_fft(pow_frames[40], title = 'pow_frames[40]')"
      ],
      "metadata": {
        "id": "OLV22Z94O22_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mel Filter Banks**: The frequency domain is then mapped to the Mel scale, which approximates the response of the human ear to different frequencies."
      ],
      "metadata": {
        "id": "yD0PbMxDDGab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting low_freq_mel to the Mel equivalent of low_freq_cut (for ex. 80 Hz), we ensure that the lowest band edge of your Mel filter bank starts at that freq."
      ],
      "metadata": {
        "id": "9U42IusN-XmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_freq_cut = 80\n",
        "low_freq_mel = 2595 * np.log10(1 + low_freq_cut / 700.0)  # Convert Hz to Mel"
      ],
      "metadata": {
        "id": "vYkPCTN5B7AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Mel filter banks\n",
        "nfilt = 40\n",
        "#low_freq_mel = 0\n",
        "high_freq_mel = (2595 * np.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
        "mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
        "bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "for m in range(1, nfilt + 1):\n",
        "    f_m_minus = int(bin[m - 1])\n",
        "    f_m = int(bin[m])\n",
        "    f_m_plus = int(bin[m + 1])\n",
        "\n",
        "    for k in range(f_m_minus, f_m):\n",
        "        fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
        "    for k in range(f_m, f_m_plus):\n",
        "        fbank[m - 1, k] = 1 - (k - bin[m]) / (bin[m + 1] - bin[m])\n",
        "\n",
        "filter_banks = np.dot(pow_frames, fbank.T)\n",
        "filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
        "filter_banks = 20 * np.log10(filter_banks)  # dB"
      ],
      "metadata": {
        "id": "Ybj5Pz9BvFZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_banks.shape"
      ],
      "metadata": {
        "id": "7dPjno8-zosM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the filter bank matrix\n",
        "plt.figure(figsize=(8,3))\n",
        "plt.imshow(filter_banks, aspect='auto', cmap='coolwarm', origin='lower')\n",
        "plt.colorbar(label='Filter Bank Value')\n",
        "plt.xlabel('Frequency Bin')\n",
        "plt.ylabel('Filter Index')\n",
        "plt.title('Mel Filter Banks')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RI0c-Vi7zu-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization**:"
      ],
      "metadata": {
        "id": "7eXF4vaa4nLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_floor_dB = -52  # Replace with your specific noise floor level in dB\n",
        "\n",
        "# Apply the noise floor\n",
        "filter_banks = np.where(filter_banks < noise_floor_dB, noise_floor_dB, filter_banks)\n",
        "\n",
        "# Optional: Normalize the Mel Filterbank Energies\n",
        "mean = np.mean(filter_banks, axis=0)\n",
        "std_dev = np.std(filter_banks, axis=0)\n",
        "std_dev[std_dev == 0] = 1e-10\n",
        "\n",
        "filter_banks -= mean\n",
        "filter_banks /= std_dev"
      ],
      "metadata": {
        "id": "VrAs5xPY6S7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the filter bank matrix\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.imshow(filter_banks, aspect='auto', cmap='coolwarm', origin='lower')\n",
        "plt.colorbar(label='Filter Bank Value')\n",
        "plt.xlabel('Frequency Bin')\n",
        "plt.ylabel('Filter Index')\n",
        "plt.title('Mel Filter Banks')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kk6d7tt240K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discrete Cosine Transform (DCT)**: The Mel frequencies are decorrelated and compressed, resulting in the final set of MFCCs."
      ],
      "metadata": {
        "id": "1Xlw0DSpDbRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Discrete Cosine Transform (DCT)\n",
        "num_ceps = 13\n",
        "mfcc = dct(filter_banks, type=2, axis=-1, norm='ortho')[:, 1 : (num_ceps + 1)]  # Exclude 0th order coefficient (energy)"
      ],
      "metadata": {
        "id": "9pfDhzydzggl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc.shape"
      ],
      "metadata": {
        "id": "60w6e6Fc1Ldg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the MFCC\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.imshow(mfcc, cmap='coolwarm', origin='lower', aspect='auto', extent=[0, 49, 1, 13])\n",
        "plt.colorbar(label='Coefficient Value')\n",
        "plt.xlabel('Frame Index')\n",
        "plt.ylabel('MFCC Coefficient Index')\n",
        "plt.title('YES - MFCC')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MwCvXvt2Dmab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a function to calc/plot mfcc"
      ],
      "metadata": {
        "id": "hdinKxgu7rIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def calc_plot_mfcc_features(audio,\n",
        "                             sample_rate,\n",
        "                             alpha = 0.97,\n",
        "                             NFFT=512,\n",
        "                             low_freq_cut=80,\n",
        "                             nfilt=40,\n",
        "                             noise_floor_dB=-52,\n",
        "                             frame_size=0.02,\n",
        "                             frame_stride=0.02,\n",
        "                             num_ceps=13,\n",
        "                             figsize=(10, 5),\n",
        "                             title= 'YES'\n",
        "                             ):\n",
        "\n",
        "    # Pre-emphasis\n",
        "    audio = np.append(audio[0], audio[1:] - alpha * audio[:-1])\n",
        "\n",
        "    # Calculate frame length and frame step (convert from seconds to samples)\n",
        "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate\n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "\n",
        "    # Calculate the total number of frames\n",
        "    num_frames = int(np.ceil(float(np.abs(len(audio) - frame_length)) / frame_step))\n",
        "\n",
        "    # Pad audio signal\n",
        "    pad_audio_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_audio_length - len(audio)))\n",
        "    pad_audio = np.append(audio, z)\n",
        "\n",
        "    # Initialize the frames\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_audio[indices.astype(np.int32, copy=False)]\n",
        "\n",
        "    # Apply window function (Hamming)\n",
        "    frames *= np.hamming(frame_length)\n",
        "\n",
        "    # Perform FFT and calculate power spectrum\n",
        "    mag_frames = np.absolute(scipy.fftpack.fft(frames, NFFT))\n",
        "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))\n",
        "\n",
        "    # Take only up to (NFFT/2) + 1 elements after the FFT,\n",
        "    # as those are the unique frequency components for real-valued signals.\n",
        "    mag_frames = mag_frames[:, :NFFT//2 + 1]\n",
        "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))\n",
        "\n",
        "    # By setting low_freq_mel to the Mel equivalent of low_freq_cut (for ex. 80 Hz),\n",
        "    # we ensure that the lowest band edge of your Mel filter bank starts at that freq.\n",
        "    low_freq_mel = 2595 * np.log10(1 + low_freq_cut / 700.0)  # Convert Hz to Mel\n",
        "\n",
        "    # Apply Mel filter banks\n",
        "    high_freq_mel = (2595 * np.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
        "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
        "    bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])\n",
        "        f_m = int(bin[m])\n",
        "        f_m_plus = int(bin[m + 1])\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = 1 - (k - bin[m]) / (bin[m + 1] - bin[m])\n",
        "\n",
        "    filter_banks = np.dot(pow_frames, fbank.T)\n",
        "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
        "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
        "\n",
        "    # Apply the noise floor\n",
        "    filter_banks = np.where(filter_banks < noise_floor_dB, noise_floor_dB, filter_banks)\n",
        "\n",
        "    # Normalize the Mel Filterbank Energies\n",
        "    mean = np.mean(filter_banks, axis=0)\n",
        "    std_dev = np.std(filter_banks, axis=0)\n",
        "    std_dev[std_dev == 0] = 1e-10\n",
        "    filter_banks -= mean\n",
        "    filter_banks /= std_dev\n",
        "\n",
        "    # Apply Discrete Cosine Transform (DCT)\n",
        "    mfcc = dct(filter_banks,\n",
        "            type=2,\n",
        "            axis=-1,\n",
        "            norm='ortho')[:, 1 : (num_ceps + 1)]  # Exclude 0th order coefficient (energy)\n",
        "\n",
        "    # Plotting the filter bank matrix\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(filter_banks, aspect='auto', cmap='coolwarm', origin='lower')\n",
        "    plt.colorbar(label='Filter Bank Value')\n",
        "    plt.xlabel('Frequency Bin')\n",
        "    plt.ylabel('Filter Index')\n",
        "    plt.title(title+' - Mel Filter Banks')\n",
        "\n",
        "    # Plotting the MFCC\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(mfcc, cmap='coolwarm', origin='lower', aspect='auto', extent=[0, 49, 1, 13])\n",
        "    plt.colorbar(label='Coefficient Value')\n",
        "    plt.xlabel('Frame Index')\n",
        "    plt.ylabel('MFCC Coefficient Index')\n",
        "    plt.title(title+' - MFCC')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "RIIukZxA7tWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_plot_mfcc_features(yes,\n",
        "                        sample_rate,\n",
        "                        alpha = 0.97,\n",
        "                        NFFT=512,\n",
        "                        low_freq_cut=80,\n",
        "                        nfilt=40,\n",
        "                        noise_floor_dB=-52,\n",
        "                        frame_size=0.02,\n",
        "                        frame_stride=0.02,\n",
        "                        num_ceps = 13,\n",
        "                        figsize = (8,4),\n",
        "                        title= 'YES'\n",
        "                             )"
      ],
      "metadata": {
        "id": "XyRIX45oAj3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_plot_mfcc_features(no,\n",
        "                        sample_rate,\n",
        "                        alpha = 0.97,\n",
        "                        NFFT=512,\n",
        "                        low_freq_cut=80,\n",
        "                        nfilt=40,\n",
        "                        noise_floor_dB=-52,\n",
        "                        frame_size=0.02,\n",
        "                        frame_stride=0.02,\n",
        "                        num_ceps = 13,\n",
        "                        figsize = (8,4),\n",
        "                        title= 'NO'\n",
        "                             )"
      ],
      "metadata": {
        "id": "2G5yauHzBP4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Image Generation"
      ],
      "metadata": {
        "id": "RBlZMCrMQzkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_signal_w_frames(audio, fs, frame_size = 0.020, frame_stride = 0.020, title = ''):\n",
        "\n",
        "    t = np.linspace(0, 1, fs, endpoint=False)  # Time array\n",
        "\n",
        "    # Define parameters for framing\n",
        "    frame_length = int(round(frame_size * fs))\n",
        "    frame_step = int(round(frame_stride * fs))\n",
        "    num_frames = int(np.ceil(float(np.abs(len(audio) - frame_length)) / frame_step))\n",
        "\n",
        "    # Create an array to hold frame boundaries\n",
        "    frame_bounds = np.arange(0, len(audio), frame_step)\n",
        "\n",
        "    # Plot the audio signal and frame boundaries\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(t, audio, label='Audio Signal')\n",
        "    for boundary in frame_bounds:\n",
        "        plt.axvline(boundary / fs, color='r', linestyle='--', linewidth=0.8)\n",
        "    plt.title('1-second '+title+' Sample with Frame Boundaries')\n",
        "    plt.xlabel('Time [s]')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XD02RXF0KalH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_signal_w_frames(yes, sample_rate, title = 'YES')\n",
        "plot_signal_w_frames(no, sample_rate, title = 'NO')"
      ],
      "metadata": {
        "id": "B2ADvBpySYdQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}